{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "import csv\n",
    "import pandas as pd\n",
    "import xlsxwriter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure: \n",
    "`\n",
    "tp-example\n",
    "   topicid\n",
    "   sourcefile\n",
    "   title\n",
    "   ilexample\n",
    "       sod_ex_index\n",
    "       sod_judgment\n",
    "       sod_bookmarks\n",
    "           sod_bookmark\n",
    "       sod_generalList\n",
    "           innerExample\n",
    "               [sod_ex_index]  (subnumbering, e.g. 1a)\n",
    "               wordgroup\n",
    "                   sod_wg_w\n",
    "                       sod_judgment\n",
    "                       sod_ex_index\n",
    "                       sod_categorialfeature\n",
    "               exampleComment \n",
    "`\n",
    "## Alternative structure\n",
    "\n",
    "`\n",
    "tp-example\n",
    "   topicid\n",
    "   sourcefile\n",
    "   title\n",
    "   ilexample\n",
    "       sod_ex_index\n",
    "       sod_judgment\n",
    "       sod_bookmarks\n",
    "           sod_bookmark\n",
    "       sod_generalList\n",
    "           innerExample\n",
    "               [sod_ex_index]  (subnumbering, e.g. 1a)\n",
    "               wordgroup\n",
    "                   lexterm\n",
    "                       word\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"tp_publ_examples_nl_syn_feb22.xml\" #\"test.xml\" #\"tp_publ_examples_nl_syn_feb22.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, sentence, judgement, sourcefile, title, ex_number):\n",
    "        self.sentence = sentence\n",
    "        self.judgement = judgement\n",
    "        self.sourcefile = sourcefile\n",
    "        self.title = title\n",
    "        self.ex_number = ex_number\n",
    "    \n",
    "    def has_questionmark_judgement(self):\n",
    "        return '?' in self.judgement\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"%s %s, which is nr. %s from file %s with title %s\" % (self.judgement, self.sentence, self.ex_number, self.sourcefile, self.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_sentences_to_csv(filename, sentences):\n",
    "    with open(filename, 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        # write the header\n",
    "        writer.writerow(['judgment','sentence', 'examplenumber', 'title', 'sourcefile'])\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            writer.writerow([sentence.judgement, sentence.sentence, sentence.ex_number, sentence.title, sentence.sourcefile])\n",
    "\n",
    "def write_sentences_to_xlsx(filename, sentences):\n",
    "    with open(filename, 'w', encoding='UTF8', newline='') as f:\n",
    "        workbook = xlsxwriter.Workbook(filename)\n",
    "        worksheet = workbook.add_worksheet()\n",
    "\n",
    "               \n",
    "        # write the header\n",
    "        worksheet.write(0, 0, 'judgment')\n",
    "        worksheet.write(0, 1, 'sentence')\n",
    "        worksheet.write(0, 2, 'examplenumber')\n",
    "        worksheet.write(0, 3, 'title')\n",
    "        worksheet.write(0, 4, 'sourcefile')\n",
    "        \n",
    "        for i, sentence in enumerate(sentences):\n",
    "            worksheet.write(i+1, 0, sentence.judgement)\n",
    "            worksheet.write(i+1, 1, sentence.sentence)\n",
    "            worksheet.write(i+1, 2, sentence.ex_number)\n",
    "            worksheet.write(i+1, 3, sentence.title)\n",
    "            worksheet.write(i+1, 4, sentence.sourcefile)\n",
    "        \n",
    "        workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_word_to_string(string, word):\n",
    "    whitespace_like = [' ', '/', '*', '\\n', '\\t', '?']\n",
    "    if len(string) == 0:\n",
    "        string += word\n",
    "    elif string[-1] in whitespace_like:\n",
    "        string += word\n",
    "    else:\n",
    "        string += ' ' + word\n",
    "    return string\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    sentence = sentence.replace('\\n', '')\n",
    "    sentence = sentence.replace('\\t', ' ')\n",
    "    sentence = sentence.replace('  ', ' ')\n",
    "    sentence = sentence.replace('                     ', ' ')\n",
    "    sentence = sentence.replace('    ', ' ')\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def append_word(word, sentence, judgement):\n",
    "    if word.nodeType == word.TEXT_NODE:\n",
    "        sentence = add_word_to_string(sentence, word.data.strip())\n",
    "    else:\n",
    "        if word.nodeName == 'sod_judgment':\n",
    "            judgement = add_word_to_string(judgement, word.firstChild.data.strip())\n",
    "            sentence = add_word_to_string(sentence, word.firstChild.data.strip())\n",
    "        else:\n",
    "            sentence = add_word_to_string(sentence,  word.toprettyxml())\n",
    "        \n",
    "        '''\n",
    "        elif word.nodeName == 'sod_emphasisitalics':\n",
    "            ### TODO TODO TODO add something \n",
    "            if word.firstChild.nodeType == word.TEXT_NODE:\n",
    "                sentence = add_word_to_string(sentence, '<i>' + word.firstChild.data.strip() + '</i>')\n",
    "            else:\n",
    "                for word2 in word.firstChild.data:\n",
    "                    sentence = add_word_to_string(sentence, '<w>' + word2.firstChild.data.strip() + '</w>')\n",
    "        elif word.nodeName == 'u':\n",
    "            sentence = add_word_to_string(sentence, '<u>' + word.firstChild.data.strip() + '</u>')\n",
    "        '''\n",
    "    return sentence, judgement\n",
    "\n",
    "\n",
    "def parse_xml_file(filename):\n",
    "    f = minidom.parse(filename)\n",
    "    ex = f.getElementsByTagName('examples')[0]\n",
    "    examples = ex.getElementsByTagName('tp-example')\n",
    "    \n",
    "\n",
    "    problems = 0\n",
    "    sentences = []\n",
    "    \n",
    "    for example in examples:\n",
    "\n",
    "        try: \n",
    "            sourcefile = example.getElementsByTagName('sourcefile')[0].firstChild.data\n",
    "            title = example.getElementsByTagName('title')[0].firstChild.toprettyxml()\n",
    "            ilexamples = example.getElementsByTagName('ilexample')\n",
    "            for ilexample in ilexamples:\n",
    "                \n",
    "                '''\n",
    "                judgement = \"\"\n",
    "                judgements = ilexample.getElementsByTagName('sod_judgment')\n",
    "\n",
    "                if len(judgements)>0:\n",
    "                    judgement = add_word_to_string(judgement, judgements[0].firstChild.data)\n",
    "                '''\n",
    "                try: \n",
    "                    il_ex_nr = ilexample.getElementsByTagName('sod_ex_index')[0].firstChild.data\n",
    "                except:\n",
    "                    il_ex_nr = \"\"\n",
    "                sod_generalists = ilexample.getElementsByTagName('sod_generalList')\n",
    "                for sod_generalist in sod_generalists:\n",
    "                    inner_examples = sod_generalist.getElementsByTagName('innerExample')\n",
    "\n",
    "                    for inner_ex in inner_examples:\n",
    "                        try: \n",
    "                            in_ex_nr = inner_ex.getElementsByTagName('sod_ex_index')[0].firstChild.data\n",
    "                        except:\n",
    "                            in_ex_nr = \"\"\n",
    "                        \n",
    "                        #print(inner_ex)\n",
    "                        wordgroups = inner_ex.getElementsByTagName('wordgroup')\n",
    "                        for wordgroup in wordgroups:\n",
    "                            sod_wg_w = wordgroup.getElementsByTagName('sod_wg_w')\n",
    "                            sentence = \"\"\n",
    "                            judgement = \"\"\n",
    "                            for words in sod_wg_w:\n",
    "                                for word in words.childNodes:\n",
    "                                    #print(word.toprettyxml())\n",
    "                                    sentence, judgement = append_word(word, sentence, judgement)\n",
    "                \n",
    "                            lexterms = wordgroup.getElementsByTagName('lexterm')\n",
    "                            for lexterm in lexterms:\n",
    "                                words = wordgroup.getElementsByTagName('word')\n",
    "                                for word in words:\n",
    "                                    sentence = add_word_to_string(sentence, word.toprettyxml())\n",
    "                            sentences.append(Sentence(clean_sentence(sentence), judgement, sourcefile, title, il_ex_nr + in_ex_nr))\n",
    "        except Exception as e:\n",
    "            print(example.toprettyxml())\n",
    "            print(str(e))\n",
    "            problems += 1\n",
    "            #print(example.toprettyxml())\n",
    "        #print(wordgroup.toprettyxml())\n",
    "    if problems>0:\n",
    "        print(\"Encountered: \" + str(problems) + \" problem sentences out of \" + str(len(examples)) + \" sentences\")\n",
    "    return sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = parse_xml_file(filename)\n",
    "print(sentences)\n",
    "write_sentences_to_xlsx('sentences.xlsx', sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sentences(sentences):\n",
    "    filtered_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if sentence.has_questionmark_judgement():\n",
    "            filtered_sentences.append(sentence)\n",
    "    return filtered_sentences\n",
    "\n",
    "filtered_sentences = filter_sentences(sentences)\n",
    "write_sentences_to_xlsx('sentences_filtered.xlsx', filtered_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<innerExample id=\"vp.3.3.3.0073\">\n",
    "<sod_ex_index>c.</sod_ex_index>\n",
    "<wordgroup><sod_wg_w id=\"w.502.c.0\">Het<sub>i</sub> </sod_wg_w><sod_wg_w id=\"w.502.c.1\">krioelt </sod_wg_w><sod_wg_w id=\"w.502.c.2\">[in de tuin]<sod_ex_index>i</sod_ex_index> </sod_wg_w><sod_wg_w id=\"w.502.c.3\">van de mieren.</sod_wg_w></wordgroup>\n",
    "<gloss><sod_gl_w id=\"g.502.c.0\">it </sod_gl_w><sod_gl_w id=\"g.502.c.1\">crawls </sod_gl_w><sod_gl_w id=\"g.502.c.2\">in the garden </sod_gl_w><sod_gl_w id=\"g.502.c.3\">of the ants</sod_gl_w></gloss>\n",
    "</innerExample>`\n",
    "\n",
    "sod_ex_index in the most inner structure simply to indicate subscript i and not used for actual example numbering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyternotebookvenv",
   "language": "python",
   "name": "jupyternotebookvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
